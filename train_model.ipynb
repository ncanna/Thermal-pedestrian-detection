{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "!pip install torchvision\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from numpy.distutils.misc_util import is_sequence\n",
    "from bs4 import BeautifulSoup  # this is to extract info from the xml, if we use it in the end\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from PIL import Image\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets, models\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "import statistics\n",
    "\n",
    "import os\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "local_mode = True\n",
    "if local_mode:\n",
    "    batch_size = 100\n",
    "    num_epochs = 2\n",
    "    epoch_partial_num = 1\n",
    "    selfcsv_df = pd.read_csv(\"frame_MasterList.csv\").head(200)\n",
    "    dir_path = os.getcwd()\n",
    "    xml_ver_string = \"xml\"\n",
    "else:\n",
    "    batch_size = 128\n",
    "    num_epochs = 100\n",
    "    epoch_partial_num = 100\n",
    "    selfcsv_df = pd.read_csv(\"frame_MasterList.csv\")\n",
    "    dir_path = \"/scratch/na3au/modelRuns\"\n",
    "    xml_ver_string = \"html.parser\"\n",
    "\n",
    "try:\n",
    "    current_time = datetime.now().strftime(\"%Y_%m_%d-%I_%M_%S_%p\")\n",
    "    directory = dir_path + \"/\" + current_time + \"_NOTEBOOK\"\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    print(f'Creation of directory at {directory} successful')\n",
    "except:\n",
    "    print(f'Creation of directory at {directory} failed')\n",
    "file_output_path = directory + \"/\"\n",
    "\n",
    "# Get label and encode\n",
    "def get_box(obj):\n",
    "    xmin = float(obj.find('xmin').text)\n",
    "    xmax = float(obj.find('xmax').text)\n",
    "    ymin = float(obj.find('ymin').text)\n",
    "    ymax = float(obj.find('ymax').text)\n",
    "    return [xmin, ymin, xmax, ymax]\n",
    "\n",
    "def get_label(obj):\n",
    "    if obj.find('name').text == 'person' or obj.find('name').text == 'people':\n",
    "        return 1\n",
    "    if obj.find('name').text == 'cyclist':\n",
    "        return 2\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# Generate the target location in the image\n",
    "def generate_target(image_id, file):\n",
    "    with open(file) as f:\n",
    "        data = f.read()\n",
    "        soup = BeautifulSoup(data, xml_ver_string)  # probably will have to change this\n",
    "        objects = soup.find_all('object')\n",
    "\n",
    "        num_objs = len(objects)\n",
    "\n",
    "        boxes = []\n",
    "        labels = []\n",
    "\n",
    "        for i in objects:\n",
    "            boxes.append(get_box(i))\n",
    "            labels.append(get_label(i))\n",
    "\n",
    "        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
    "        labels = torch.as_tensor(labels, dtype=torch.int64)\n",
    "        img_id = torch.tensor([image_id])\n",
    "\n",
    "        # Creating the target for the box\n",
    "        target = {}\n",
    "        target['boxes'] = boxes\n",
    "        target['labels'] = labels\n",
    "        target['image_id'] = img_id\n",
    "\n",
    "        return target\n",
    "\n",
    "def OHE(label):\n",
    "    if label == \"People\" or label == \"Person\":\n",
    "        return 1\n",
    "    elif label == \"Cyclist\":\n",
    "        return 2\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def Recode(label):\n",
    "    if label == 1:\n",
    "        return \"Person(s)\"\n",
    "    elif label == 2:\n",
    "        return \"Cyclist\"\n",
    "    else:\n",
    "        return \"N/A\"\n",
    "\n",
    "class FullImages(object):\n",
    "    def __init__(self, transforms=None):\n",
    "        self.csv = selfcsv_df\n",
    "        self.csv_len = self.csv.shape[1]\n",
    "        self.imgs = self.csv.image_path.tolist()\n",
    "        self.imgs_len = len(self.imgs)\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.imgs_len\n",
    "        # return self.csv_len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        img = self.csv.loc[idx, 'image_path']\n",
    "        annotation = self.csv.loc[idx, 'annotation_path']\n",
    "\n",
    "        img = Image.open(img).convert(\"L\")\n",
    "        target = generate_target(idx, annotation)\n",
    "\n",
    "        # label = self.labels[idx]\n",
    "        # label = OHE(label)\n",
    "        # label = torch.as_tensor(label, dtype=torch.int64)\n",
    "\n",
    "        if self.transforms is not None:\n",
    "            img = self.transforms(img)\n",
    "\n",
    "        return img, target\n",
    "\n",
    "# Normalize\n",
    "data_transform = transforms.Compose([  # transforms.Resize((80,50)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5]\n",
    "                         )])\n",
    "\n",
    "# Collate images\n",
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))  # will need adjusting when pathing is adjusted\n",
    "\n",
    "dataset = FullImages(data_transform)\n",
    "data_size = len(dataset)\n",
    "print(f'Length of Dataset: {data_size}')\n",
    "\n",
    "indices = list(range(data_size))\n",
    "test_split = 0.2\n",
    "split = int(np.floor(test_split * data_size))\n",
    "# print(f'Length of Split Dataset: {split}')\n",
    "\n",
    "train_indices, test_indices = indices[split:], indices[:split]\n",
    "len_train_ind, len_test_ind = len(train_indices), len(test_indices)\n",
    "print(f'Length of Train: {len_train_ind}; Length of Test: {len_test_ind}')\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "test_sampler = SubsetRandomSampler(test_indices)\n",
    "\n",
    "data_loader = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    batch_size=batch_size,\n",
    "    sampler=train_sampler,\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "len_dataloader = len(data_loader)\n",
    "data_loader_test = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=test_sampler,\n",
    "                                               collate_fn=collate_fn)\n",
    "len_testdataloader = len(data_loader_test)\n",
    "print(f'Length of test: {len_testdataloader}; Length of train: {len_dataloader}')\n",
    "\n",
    "# Check if GPU\n",
    "cuda = torch.cuda.is_available()\n",
    "if cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f'CUDA device')\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(f'CPU device')\n",
    "\n",
    "# Instance segmentation is crucial in using the full images\n",
    "def get_model_instance_segmentation(num_classes):\n",
    "    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(\n",
    "        in_features, num_classes)\n",
    "    return model\n",
    "\n",
    "# print(f'{len_testdataloader} batches in test data loader.')\n",
    "# print(f'{len_dataloader} batches in train data loader.')\n",
    "\n",
    "# cnn = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained = False)\n",
    "model = get_model_instance_segmentation(3)\n",
    "model.to(device)\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.Adam(params)  # , lr = 0.005, weight_decay = 0.0005)\n",
    "\n",
    "tot_ats = 0\n",
    "epochs = 0\n",
    "epoch_ats = []\n",
    "epoch_losses = []\n",
    "df = pd.DataFrame({'Mean_Epoch_Loss': epoch_losses})\n",
    "for epoch in range(num_epochs):\n",
    "    epochs += 1\n",
    "    print(f'Epoch: {epochs}')\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    i = 0\n",
    "    for train_imgs, train_annotations in data_loader:\n",
    "        imgs = list(img.to(device) for img in train_imgs)\n",
    "        annotations = [{k: v.to(device) for k, v in t.items()} for t in train_annotations]\n",
    "        loss_dict = model([imgs[0]], [annotations[0]])\n",
    "        losses = sum(loss for loss in loss_dict.values())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        losses.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        i += 1\n",
    "        tot_ats += 1\n",
    "\n",
    "        epoch_loss += losses\n",
    "        print(f'Iteration: {i}/{len_dataloader}, Loss: {losses}')\n",
    "\n",
    "    mean_epoch_loss = epoch_loss / i\n",
    "    epoch_losses.append(mean_epoch_loss)\n",
    "    epoch_ats.append(i)\n",
    "\n",
    "try:\n",
    "    # Save training metrics\n",
    "    full_name = \"full_model_losses_\" + str(epochs) + \".csv\"\n",
    "    df.to_csv(file_output_path + full_name, index=False)\n",
    "    #print(f'Full model losses for {epochs} epochs saved to {directory}.')\n",
    "except:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    # Save model\n",
    "    torch.save(model.state_dict(), file_output_path + 'full_model.pt')\n",
    "    #print(f'Full model trained on {epochs} epochs saved to {directory}.')\n",
    "except:\n",
    "    pass\n",
    "\n",
    "#print(f'Annotations Trained: {tot_ats}')\n",
    "#print(epoch_ats)\n",
    "\n",
    "for test_imgs, test_annotations in data_loader_test:\n",
    "    imgs_test = list(img_test.to(device) for img_test in test_imgs)\n",
    "    annotations_test = [{k: v.to(device) for k, v in t.items()} for t in test_annotations]\n",
    "\n",
    "for train_imgs, train_annotations in data_loader:\n",
    "    imgs_train = list(img_train.to(device) for img_train in train_imgs)\n",
    "    annotations_train = [{k: v.to(device) for k, v in t.items()} for t in train_annotations]\n",
    "\n",
    "# imgs_train = [t.to(device) for t in imgs_train]\n",
    "# imgs_test = [t.to(device) for t in imgs_test]\n",
    "\n",
    "train_annotations = [{'boxes': d['boxes'].to(device), 'labels': d['labels'].to(device),\n",
    "                      'image_id': d['image_id'].to(device)} for d in train_annotations]\n",
    "test_annotations = [{'boxes': d['boxes'].to(device), 'labels': d['labels'].to(device),\n",
    "                     'image_id': d['image_id'].to(device)} for d in test_annotations]\n",
    "\n",
    "master_csv = pd.read_csv(\"frame_MasterList.csv\")\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "preds_train = model(imgs_train)\n",
    "print(\"Train predictions\")\n",
    "print(preds_train)\n",
    "\n",
    "preds_test = model(imgs_test)\n",
    "print(\"Test predictions\")\n",
    "print(preds_test)\n",
    "\n",
    "print(len(train_annotations))\n",
    "print(len(test_annotations))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "preds_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "try:\n",
    "    if preds_train == preds_test:\n",
    "        print(f'Train predictions EQUAL test predictions.')\n",
    "    else:\n",
    "        print(f'Train predictions DO NOT EQUAL test predictions.')\n",
    "except:\n",
    "    pass\n",
    "\n",
    "def get_iou(num, input, test=False):\n",
    "    if test:\n",
    "        identifier = \"Test\"\n",
    "        annotation = annotations_test[num]\n",
    "        prediction = preds_test[num]\n",
    "    else:\n",
    "        identifier = \"Train\"\n",
    "        annotation = annotations[num]\n",
    "        prediction = preds_train[num]\n",
    "\n",
    "    annotation_boxes = annotation[\"boxes\"].tolist()\n",
    "\n",
    "    ix = 0\n",
    "    for box in annotation[\"boxes\"]:\n",
    "        img_id = annotation[\"image_id\"].item()\n",
    "        file_name = master_csv.loc[img_id, :].image_path\n",
    "        set = file_name.split(\"/\")[7]\n",
    "        video = file_name.split(\"/\")[8]\n",
    "        file_name = file_name.split(\"/\")[10]\n",
    "        file_name = file_name[:-4]\n",
    "        output_name = set + \"_\" + video + \"_\" + file_name\n",
    "        ix += 1\n",
    "\n",
    "    ix = 0\n",
    "    voc_iou = []\n",
    "    #print(f'{len(prediction[\"boxes\"])} prediction boxes made for {len(annotation[\"boxes\"])}\n",
    "    # actual boxes in {str(output_name)} for {identifier} with note {input}')\n",
    "    for box in prediction[\"boxes\"]:\n",
    "        xmin, ymin, xmax, ymax = box.tolist()\n",
    "        iou_list = []\n",
    "        for bound in annotation_boxes:\n",
    "            a_xmin, a_ymin, a_xmax, a_ymax = bound\n",
    "            xA = max(xmin, a_xmin)\n",
    "            yA = max(ymin, a_ymin)\n",
    "            xB = min(xmax, a_xmax)\n",
    "            yB = min(ymax, a_ymax)\n",
    "            interArea = max(0, xB - xA + 1) * max(0, yB - yA + 1)\n",
    "            p_area = (xmax - xmin + 1) * (ymax - ymin + 1)\n",
    "            a_area = (a_xmax - a_xmin + 1) * (a_ymax - a_ymin + 1)\n",
    "            iou = interArea / float(p_area + a_area - interArea)\n",
    "            iou_list.append(iou)\n",
    "        max_val = max(iou_list)\n",
    "        voc_iou.append(max_val)\n",
    "        ix += 1\n",
    "\n",
    "    if len(voc_iou) == 0:\n",
    "        mean_iou = 0\n",
    "        print(f'No predictions made so Mean IOU: {mean_iou}')\n",
    "    else:\n",
    "        mean_iou = sum(voc_iou) / len(voc_iou)\n",
    "\n",
    "    return [mean_iou, voc_iou]\n",
    "\n",
    "\n",
    "def plot_images(num, input):\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=2)\n",
    "    img_tensor = imgs[num]\n",
    "    annotation = annotations[num]\n",
    "    # for key, value in annotation.items():\n",
    "    #         print(key, value)\n",
    "    prediction = preds_train[num]\n",
    "\n",
    "    img = img_tensor.cpu().data\n",
    "    img = img[0, :, :]\n",
    "\n",
    "    ax[0].imshow(img, cmap='gray')\n",
    "    ax[1].imshow(img, cmap='gray')\n",
    "\n",
    "    ix = 0\n",
    "    for box in annotation[\"boxes\"]:\n",
    "        # print(annotations[ix])\n",
    "        xmin, ymin, xmax, ymax = box.tolist()\n",
    "        value = annotation[\"labels\"][ix]\n",
    "        img_id = annotation[\"image_id\"].item()\n",
    "        file_name = master_csv.loc[img_id, :].image_path\n",
    "        set = file_name.split(\"/\")[7]\n",
    "        video = file_name.split(\"/\")[8]\n",
    "        file_name = file_name.split(\"/\")[10]\n",
    "        file_name = file_name[:-4]\n",
    "        output_name = set + \"_\" + video + \"_\" + file_name\n",
    "        text = Recode(value)\n",
    "        colors = [\"r\", \"#00FF00\", \"#0000FF\"]\n",
    "        rect = patches.Rectangle((xmin, ymin), (xmax - xmin), (ymax - ymin), linewidth=1,\n",
    "                                 edgecolor=colors[value], facecolor='none')\n",
    "        target_x = xmin\n",
    "        target_y = ymin - 5\n",
    "        ax[0].text(target_x, target_y, text, color=colors[value])\n",
    "        ax[0].add_patch(rect)\n",
    "        ix += 1\n",
    "\n",
    "    ix = 0\n",
    "    print(str(len(prediction[\"boxes\"])) + \" prediction boxes made for \" + str(\n",
    "        len(annotation[\"boxes\"])) + \" actual boxes in \" + str(output_name))\n",
    "    for box in prediction[\"boxes\"]:\n",
    "        xmin, ymin, xmax, ymax = box.tolist()\n",
    "        value = prediction[\"labels\"][ix]\n",
    "        text = Recode(value)\n",
    "        colors = [\"r\", \"#00FF00\", \"#0000FF\"]\n",
    "        rect = patches.Rectangle((xmin, ymin), (xmax - xmin), (ymax - ymin), linewidth=1,\n",
    "                                 edgecolor=colors[value], facecolor='none')\n",
    "        target_x = xmin\n",
    "        target_y = ymin - 5\n",
    "        ax[1].text(target_x, target_y, text, color=colors[value])\n",
    "        ax[1].add_patch(rect)\n",
    "        ix += 1\n",
    "\n",
    "    # figname = file_name+\"_\"+input+\".png\"\n",
    "    # fig.savefig(figname)\n",
    "    plt.show()\n",
    "\n",
    "def plot_iou(num, input, test=False):\n",
    "    fig, ax = plt.subplots(1)\n",
    "    if test:\n",
    "        identifier = \"Test\"\n",
    "        print(identifier)\n",
    "        img_tensor = imgs_test[num]\n",
    "        annotation = annotations_test[num]\n",
    "        prediction = preds_test[num]\n",
    "    else:\n",
    "        identifier = \"Train\"\n",
    "        print(identifier)\n",
    "        img_tensor = imgs[num]\n",
    "        annotation = annotations[num]\n",
    "        prediction = preds_train[num]\n",
    "\n",
    "    img = img_tensor.cpu().data\n",
    "    img = img[0, :, :]\n",
    "    annotation_boxes = annotation[\"boxes\"].tolist()\n",
    "\n",
    "    ax.imshow(img, cmap='gray')\n",
    "\n",
    "    ix = 0\n",
    "    for box in annotation[\"boxes\"]:\n",
    "        xmin, ymin, xmax, ymax = box.tolist()\n",
    "        value = annotation[\"labels\"][ix]\n",
    "        img_id = annotation[\"image_id\"].item()\n",
    "        file_name = master_csv.loc[img_id, :].image_path\n",
    "        set = file_name.split(\"/\")[7]\n",
    "        video = file_name.split(\"/\")[8]\n",
    "        file_name = file_name.split(\"/\")[10]\n",
    "        file_name = file_name[:-4]\n",
    "        output_name = set + \"_\" + video + \"_\" + file_name + \"_\" + identifier\n",
    "        text = Recode(value)\n",
    "        colors = [\"r\", \"r\", \"r\"]\n",
    "        rect = patches.Rectangle((xmin, ymin), (xmax - xmin), (ymax - ymin), linewidth=1,\n",
    "                                 edgecolor=colors[value], facecolor='none')\n",
    "        target_x = xmin\n",
    "        target_y = ymin - 5\n",
    "        ax.text(target_x, target_y, text, color=colors[value])\n",
    "        ax.add_patch(rect)\n",
    "        ix += 1\n",
    "\n",
    "    ix = 0\n",
    "    voc_iou = []\n",
    "    print(\n",
    "        f'{len(prediction[\"boxes\"])} prediction boxes made for {len(annotation[\"boxes\"])} actual boxes in {str(output_name)} for {identifier} with note {input} (INDEX {num})')\n",
    "    for box in prediction[\"boxes\"]:\n",
    "        xmin, ymin, xmax, ymax = box.tolist()\n",
    "\n",
    "        iou_list = []\n",
    "        for bound in annotation_boxes:\n",
    "            a_xmin, a_ymin, a_xmax, a_ymax = bound\n",
    "            xA = max(xmin, a_xmin)\n",
    "            yA = max(ymin, a_ymin)\n",
    "            xB = min(xmax, a_xmax)\n",
    "            yB = min(ymax, a_ymax)\n",
    "            interArea = max(0, xB - xA + 1) * max(0, yB - yA + 1)\n",
    "            p_area = (xmax - xmin + 1) * (ymax - ymin + 1)\n",
    "            a_area = (a_xmax - a_xmin + 1) * (a_ymax - a_ymin + 1)\n",
    "            iou = interArea / float(p_area + a_area - interArea)\n",
    "            iou_list.append(iou)\n",
    "        max_val = max(iou_list)\n",
    "        voc_iou.append(max_val)\n",
    "\n",
    "        max_ix = iou_list.index(max_val)\n",
    "        map_dict = {max_ix: max_val}\n",
    "\n",
    "        # iou_string = ', '.join((str(float) for float in iou_list))\n",
    "        value = prediction[\"labels\"][ix]\n",
    "        text = json.dumps(map_dict)\n",
    "        colors = [\"r\", \"#00FF00\", \"#0000FF\"]\n",
    "        rect = patches.Rectangle((xmin, ymin), (xmax - xmin), (ymax - ymin), linewidth=1,\n",
    "                                 edgecolor=colors[value], facecolor='none')\n",
    "        target_x = xmin\n",
    "        target_y = ymin - 5\n",
    "        ax.text(target_x, target_y, text, color=colors[value])\n",
    "        ax.add_patch(rect)\n",
    "        ix += 1\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    if len(voc_iou) == 0:\n",
    "        mean_iou = 0\n",
    "        print(f'No predictions made so Mean IOU: {mean_iou}')\n",
    "    else:\n",
    "        mean_iou = sum(voc_iou) / len(voc_iou)\n",
    "        fp = voc_iou.count(0) / len(voc_iou) * 100\n",
    "        bp = sum((i > 0 and i < 0.5) for i in voc_iou) / len(voc_iou) * 100\n",
    "        gp = sum((i >= 0.5) for i in voc_iou) / len(voc_iou) * 100\n",
    "        print(f'{fp} false positives (IOU = 0)')\n",
    "        print(f'{bp} bad positives (0 < IOU < 0.5)')\n",
    "        print(f'{gp} good positives (IOU >= 0.5)')\n",
    "        print(f'Mean IOU: {mean_iou}')\n",
    "\n",
    "    figname = output_name + \"_\" + input + \".png\"\n",
    "    fig.savefig(file_output_path + figname)\n",
    "    #print(f'Figure {figname} saved to {directory}.')\n",
    "\n",
    "print(f'Train is {len(preds_train)} and test is {len(preds_test)}')\n",
    "plot_images(0, \"first\")\n",
    "\n",
    "plot_iou(0, \"first\", False)\n",
    "plot_iou(len(preds_train) - 1, \"last\", False)\n",
    "get_iou(len(preds_train) - 1, \"last\", False)[0]\n",
    "\n",
    "plot_iou(0, \"first\", True)\n",
    "plot_iou(len(preds_test) - 1, \"last\", True)\n",
    "get_iou(len(preds_test) - 1, \"last\", True)[0]\n",
    "\n",
    "iou_df_train = pd.DataFrame(columns=[\"Train_Mean_IOU\", \"IOU_List\"])\n",
    "iou_df_train_name = \"full_iou_TRAIN_\" + str(epochs) + \".csv\"\n",
    "for train_pred in range(0, len(preds_train)):\n",
    "    iou_function = get_iou(train_pred, \"first\", False)\n",
    "    len_df = len(iou_df_train)\n",
    "    iou_df_train.loc[len_df, :] = iou_function\n",
    "    try:\n",
    "        if train_pred % 50 == 0:\n",
    "            partial_name = \"partial_iou_TRAIN_\" + str(train_pred) + \"_images.csv\"\n",
    "            iou_df_train.to_csv(file_output_path + iou_df_train_name, index=False)\n",
    "            print(f'Partial train IOUs for {len(iou_df_train)} images saved to {directory}.')\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "iou_df_train.to_csv(file_output_path + iou_df_train_name, index=False)\n",
    "print(f'Full train IOUs for {len(iou_df_train)} images saved to {directory}.')\n",
    "print(iou_df_train.sort_values(by='Train_Mean_IOU', ascending=False).head(5))\n",
    "\n",
    "iou_df_test = pd.DataFrame(columns=[\"Test_Mean_IOU\", \"IOU_List\"])\n",
    "iou_df_test_name = \"full_iou_TEST_\" + str(epochs) + \".csv\"\n",
    "for test_pred in range(0, len_testdataloader):\n",
    "    iou_function = get_iou(test_pred, \"test\", False)\n",
    "    len_df = len(iou_df_test)\n",
    "    iou_df_test.loc[len_df, :] = iou_function\n",
    "    try:\n",
    "        if test_pred % 50 == 0:\n",
    "            partial_name = \"partial_iou_TEST_\" + str(test_pred) + \"_images.csv\"\n",
    "            iou_df_test.to_csv(file_output_path + iou_df_test_name, index=False)\n",
    "            print(f'Partial train IOUs for {len(iou_df_test)} images saved to {directory}.')\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "iou_df_test.to_csv(file_output_path + iou_df_test_name, index=False)\n",
    "print(f'Full train IOUs for {len(iou_df_test)} images saved to {directory}.')\n",
    "print(iou_df_test.sort_values(by='Test_Mean_IOU', ascending=False).head(5))\n",
    "\n",
    "max_train_ix = iou_df_train[iou_df_train['Train_Mean_IOU'] == iou_df_train['Train_Mean_IOU'].max()].index.tolist()[0]\n",
    "max_test_ix = iou_df_test[iou_df_test['Test_Mean_IOU'] == iou_df_test['Test_Mean_IOU'].max()].index.tolist()[0]\n",
    "\n",
    "plot_iou(max_train_ix, \"best\", False)\n",
    "plot_iou(max_test_ix, \"best\", True)\n",
    "\n",
    "print(f'Train Mean IOU: {iou_df_train[\"Train_Mean_IOU\"].mean()}')\n",
    "print(f'Test Mean IOU: {iou_df_test[\"Test_Mean_IOU\"].mean()}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
